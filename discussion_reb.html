<center>
	The columns indicate the approaches benchmarked in the paper (Fig. 8), the single image on the second row is the interpretation (mask * input) extracted using the GradCAM approach (<a href="https://arxiv.org/pdf/1610.02391.pdf">arxiv</a>, <a href="https://github.com/jacobgil/pytorch-grad-cam">github</a>). <br> The single image on the third row is the mask generated from GradCAM.
	<br>
	<br>
	<br>
	<img src="samples/screen.png"> <br><br> <img width=300 src="samples/gradcam.png"> <br><br> <img width=300 src="samples/mask.png">
</center>
